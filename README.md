# Adversarial_Attacks_on_Image_Vision
This study explores the effectiveness of three adversarial attack algorithms, which are FGSM, BIM and PGD on three popular ImageNet pretrained neural network models: ResNet50, MobileNet_v2, and Inception_v3. Additionally, defense algorithm 'feature squeezing' is applied

You can find the related dataset on the link below. I used Google Colab environment and GPU runtime. 
https://www.kaggle.com/competitions/nips-2017-defense-against-adversarial-attack

PS: To better understand the concept of adversarial attacks and defenses and how they work, in this project any library specifically designed for adversarial attacks or defenses is not used, but you can always exploit the available libraries with more options
